# Техническое видение проекта: LLM-ассистент Telegram-бот

## Введение

Данный документ описывает техническое видение проекта LLM-ассистента в виде Telegram-бота. Документ служит отправной точкой и техническим проектом для разработки MVP решения.

**Цель**: Создать максимально простое решение для проверки идеи интеллектуального Telegram-бота на основе LLM.

**Принципы**: KISS (Keep It Simple, Stupid) и ООП с принципом "один класс - один файл". Никакого оверинжиниринга.

---

## 1. Технологии

### Основной стек

- **Python 3.11+** - основной язык разработки
- **uv** - управление зависимостями и виртуальным окружением
- **aiogram 3.x** - асинхронный фреймворк для Telegram Bot API (polling)
- **openai** - клиент для работы с OpenRouter API
- **make** - автоматизация команд (run, install, clean)

### Вспомогательные библиотеки

- **python-dotenv** - загрузка конфигурации из `.env`
- **pydantic** - валидация конфигурации
- **aiofiles** - асинхронная работа с файлами

### Инструменты разработки

- **ruff** - линтер и форматтер кода (замена flake8, black, isort)
- **mypy** - статическая проверка типов
- **pytest** - фреймворк для тестирования
- **pytest-asyncio** - поддержка async тестов
- **pytest-cov** - измерение покрытия кода тестами
- **pre-commit** - автоматическая проверка перед коммитом

### Хранение данных

- **In-memory** хранилище для активных диалогов
- **Файловая система** для персистентности (JSON файлы)
- **Ограничение истории**: последние N сообщений на пользователя

### Окружение

- **Polling** для получения обновлений от Telegram
- **Docker** для разработки (опционально, приложение работает и без Docker)
- Без внешней БД

### Обоснование выбора

- Все технологии проверенные и простые в использовании
- Минимальные требования к инфраструктуре
- Быстрый старт разработки и тестирования идеи

---

## 2. Принципы разработки

### 1. KISS (Keep It Simple, Stupid)
- Простые решения вместо сложных
- Избегаем преждевременной оптимизации
- Код должен быть понятен с первого взгляда

### 2. ООП с четкой структурой
- Один класс = один файл
- Один класс = одна ответственность (SRP)
- Никаких "божественных объектов"

### 3. Читаемость кода
- Говорящие имена переменных и функций
- Короткие функции (до 20-30 строк)
- Минимум вложенности

### 4. Документирование
- Docstring для всех публичных методов и функций
- Описание параметров, возвращаемых значений и исключений
- Документирование контрактов (интерфейсов/протоколов)

### 5. Логирование
- Логируем все ключевые события приложения
- Разные уровни логов (DEBUG, INFO, WARNING, ERROR)
- Логи помогают отслеживать работу и находить проблемы

### 6. Асинхронность
- Используем async/await где необходимо
- Не блокируем event loop

### 7. Минимализм
- Только необходимые зависимости
- Только необходимый функционал для MVP
- Без "а вдруг пригодится"

### 8. Типизация
- Type hints для всех функций и методов
- Помогает избежать ошибок и улучшает читаемость

### 9. Качество кода
- Автоматическое форматирование (Ruff)
- Проверка линтером перед каждым коммитом
- Статическая проверка типов (Mypy)
- Pre-commit hooks для автоматизации

### 10. Тестирование
- Unit-тесты для критической логики
- Минимальное покрытие: 70% для Storage и LLMClient
- Async тесты через pytest-asyncio
- Моки для внешних API

### 11. SOLID принципы
- **S**ingle Responsibility - один класс/функция = одна задача
- **O**pen/Closed - открыт для расширения, закрыт для модификации
- **L**iskov Substitution - соблюдение контрактов
- **I**nterface Segregation - маленькие специфичные интерфейсы
- **D**ependency Inversion - зависимость от абстракций

### 12. DRY (Don't Repeat Yourself)
- Избегаем дублирования кода
- Выносим общую логику в функции и утилиты
- Используем декораторы для повторяющихся паттернов

---

## 3. Структура проекта

```
ai-tg-bot/
├── src/
│   ├── __init__.py
│   ├── bot.py              # Основной класс бота (Bot)
│   ├── config.py           # Конфигурация (Config)
│   ├── llm_client.py       # Клиент для работы с LLM (LLMClient)
│   ├── storage.py          # Хранилище диалогов (Storage)
│   ├── main.py             # Точка входа
│   ├── handlers/           # Обработчики команд и сообщений
│   │   ├── __init__.py
│   │   ├── commands.py     # /start, /help, /role, /status, /reset
│   │   └── messages.py     # Обработчик текстовых сообщений
│   └── utils/              # Вспомогательные утилиты
│       ├── __init__.py
│       ├── message_splitter.py  # Разбивка длинных сообщений
│       └── error_formatter.py   # Форматирование ошибок
├── data/                   # JSON файлы с историей диалогов
│   └── .gitkeep
├── logs/                   # Логи приложения
│   └── .gitkeep
├── docs/                   # Документация
│   ├── idea.md
│   ├── vision.md
│   ├── tasklist.md
│   └── techDebtTasklist.md
├── tests/                  # Unit-тесты
│   ├── __init__.py
│   ├── conftest.py         # Фикстуры
│   ├── test_storage.py
│   ├── test_llm_client.py
│   └── test_handlers.py
├── .cursor/                # Cursor IDE правила
│   └── rules/
│       ├── conventions.mdc
│       └── workflow.mdc
├── .env.example            # Пример конфигурации
├── .env                    # Конфигурация (не в git)
├── .gitignore
├── .dockerignore           # Исключения для Docker
├── .pre-commit-config.yaml # Pre-commit hooks конфигурация
├── Dockerfile.dev          # Docker образ для разработки
├── docker-compose.yml      # Docker Compose конфигурация
├── Makefile                # Команды для управления проектом
├── pyproject.toml          # uv конфигурация и зависимости
└── README.md
```

### Описание компонентов

**Исходный код:**
- **main.py** - точка входа, запуск приложения, парсинг CLI аргументов
- **bot.py** - инициализация и запуск Telegram бота (упрощен до ~100 строк)
- **config.py** - загрузка и валидация настроек из `.env`
- **llm_client.py** - взаимодействие с OpenRouter API
- **storage.py** - сохранение/загрузка истории диалогов в JSON (async I/O через aiofiles)
- **handlers/commands.py** - обработчики команд (/start, /help, /role, /status, /reset)
- **handlers/messages.py** - обработчик текстовых сообщений
- **utils/message_splitter.py** - разбивка длинных сообщений на части
- **utils/error_formatter.py** - форматирование сообщений об ошибках

**Данные и логи:**
- **data/** - директория для хранения JSON файлов с историей
- **logs/** - директория для файлов логов

**DevOps и конфигурация:**
- **Dockerfile.dev** - Docker образ для разработки (Alpine-based)
- **docker-compose.yml** - оркестрация Docker контейнера
- **.dockerignore** - исключения при сборке образа
- **Makefile** - команды для запуска и управления проектом
- **.env** / **.env.example** - переменные окружения

### Принципы организации

- Один класс = один файл
- Плоская структура без глубокой вложенности
- Понятные имена файлов, соответствующие назначению

---

## 4. Архитектура проекта

### Компоненты системы

#### 1. Bot
- Инициализирует aiogram dispatcher и bot
- Регистрирует handlers
- Запускает polling
- Координирует работу всех компонентов

#### 2. MessageHandler
- Получает команды и сообщения от пользователя
- Обрабатывает команды: `/start`, `/role`, `/reset`, `/status`, `/help`
- Для обычных сообщений:
  - Показывает typing action (индикатор "печатает...")
  - Загружает историю диалога через Storage
  - Отправляет запрос в LLMClient с историей
  - Сохраняет обновленную историю
  - Отправляет ответ пользователю (разбивает на части если >4096 символов)

#### 3. LLMClient
- Формирует запрос к OpenRouter API
- Добавляет системный промпт к истории
- Отправляет запрос и получает ответ модели
- **Fallback механизм**: автоматическое переключение на резервную модель при сбоях
- Возвращает текст ответа

#### 4. Storage
- Загрузка истории диалога из JSON файла
- Сохранение истории диалога в JSON файл
- Ограничение количества сообщений в истории
- Управление файлами по user_id

#### 5. Config
- Загрузка переменных окружения из .env
- Валидация настроек через Pydantic
- Предоставление настроек другим компонентам

### Поток данных

```
Пользователь Telegram
        ↓
    Bot (aiogram)
        ↓
  MessageHandler ←→ Storage ←→ JSON файлы
        ↓
   LLMClient
        ↓
  OpenRouter API
        ↓
    Ответ LLM
        ↓
  MessageHandler
        ↓
    Bot (aiogram)
        ↓
Пользователь Telegram
```

### Принципы взаимодействия

- Слабая связанность компонентов
- Каждый компонент решает одну задачу
- Простые интерфейсы между компонентами
- Асинхронное взаимодействие где необходимо

---

## 5. Модель данных

### 1. Сообщение (Message)

```python
{
    "role": "user" | "assistant" | "system",
    "content": "текст сообщения",
    "timestamp": "2025-10-10T12:00:00"
}
```

### 2. История диалога (Dialog)

```python
{
    "user_id": 123456789,
    "messages": [
        {
            "role": "system", 
            "content": "системный промпт",
            "timestamp": "2025-10-10T12:00:00"
        },
        {
            "role": "user", 
            "content": "привет",
            "timestamp": "2025-10-10T12:00:05"
        },
        {
            "role": "assistant", 
            "content": "здравствуйте",
            "timestamp": "2025-10-10T12:00:07"
        }
    ],
    "updated_at": "2025-10-10T12:00:07"
}
```

### 3. Конфигурация (Config)

```python
{
    "telegram_token": "...",
    "openrouter_api_key": "...",
    "openrouter_base_url": "https://openrouter.ai/api/v1",
    "openrouter_model": "anthropic/claude-3.5-sonnet",
    "openrouter_fallback_model": "meta-llama/llama-3.1-8b-instruct:free",
    "system_prompt": "Ты полезный ассистент...",
    "max_history_messages": 50,
    "llm_temperature": 0.7,
    "llm_max_tokens": 1000,
    "retry_attempts": 3,
    "retry_delay": 1.0,
    "log_level": "INFO",
    "data_dir": "data",
    "logs_dir": "logs"
}
```

### Хранение на диске

- Один JSON файл на пользователя: `data/{user_id}.json`
- Формат файла соответствует структуре Dialog
- Timestamp в формате ISO 8601
- Автоматическое обновление `updated_at` при каждом сохранении

### Принципы работы с данными

- Простая JSON сериализация/десериализация
- Валидация через Pydantic модели
- Ограничение истории для экономии памяти и токенов LLM

---

## 6. Работа с LLM

### Подключение к OpenRouter

- Используем библиотеку `openai`
- OpenRouter совместим с OpenAI API
- Базовый URL из конфигурации: `openrouter_base_url`
- API ключ из конфигурации: `openrouter_api_key`
- Модель из конфигурации: `openrouter_model`

### Формирование запроса

1. Загружаем историю диалога пользователя из Storage
2. Добавляем системный промпт первым сообщением (если его нет в истории)
3. Ограничиваем количество сообщений (`max_history_messages`)
4. Формируем запрос в формате OpenAI Chat Completions API

### Параметры запроса

- `model` - из конфигурации (`openrouter_model`)
- `messages` - история диалога с системным промптом
- `temperature` - 0.7 (из конфигурации `llm_temperature`)
- `max_tokens` - 1000 (из конфигурации `llm_max_tokens`)

### Обработка ответа

- Извлекаем текст ответа из `choices[0].message.content`
- **Логируем использование токенов**: 
  - `prompt_tokens` - токены в запросе
  - `completion_tokens` - токены в ответе
  - `total_tokens` - общее количество
- Возвращаем текст ответа для отправки пользователю

### Обработка ошибок и retry

- **Retry механизм** для временных сбоев:
  - Количество попыток: `retry_attempts` (по умолчанию 3)
  - Задержка между попытками: `retry_delay` с экспоненциальным ростом
- Обрабатываем типы ошибок:
  - Rate limit errors
  - Timeout errors
  - Connection errors
  - API errors
- Логируем все ошибки с полным контекстом
- При провале всех попыток возвращаем понятное сообщение пользователю

### Fallback механизм

- **Резервная модель** для повышения надежности:
  - Основная модель: `openrouter_model` (например, claude-3.5-sonnet)
  - Fallback модель: `openrouter_fallback_model` (например, llama-3.1-8b-instruct:free)
- **Автоматическое переключение** на fallback модель:
  - При недоступности основной модели (503, 500 ошибки)
  - При превышении rate limits основной модели (429 ошибка)
  - После исчерпания всех retry попыток основной модели
- **Логика работы**:
  1. Попытка запроса к основной модели с retry механизмом
  2. При неудаче - автоматическое переключение на fallback модель
  3. Попытка запроса к fallback модели с retry механизмом
  4. При неудаче fallback модели - сообщение пользователю о недоступности
- **Логирование fallback операций**:
  - Причина переключения на fallback (тип ошибки основной модели)
  - Успешное использование fallback модели
  - Отказ обеих моделей с полным контекстом

### Логирование LLM операций

- Каждый запрос: модель, количество сообщений в истории, user_id
- Каждый ответ: использованные токены, время выполнения запроса
- Все ошибки: тип ошибки, детали, количество попыток
- **Fallback операции**: переключение на резервную модель, причина, результат
- Уровни логирования:
  - INFO - успешные запросы и ответы
  - WARNING - retry попытки, переключение на fallback модель
  - ERROR - финальные ошибки после всех retry обеих моделей

---

## 7. Сценарии работы

### 1. Начало работы - `/start`

- Пользователь отправляет команду `/start`
- Бот приветствует и объясняет свои возможности
- Создается новый диалог с системным промптом по умолчанию
- Показывает список доступных команд

### 2. Основной сценарий - диалог

- Пользователь отправляет текстовое сообщение
- **Бот показывает индикатор "печатает..."** (typing action)
- Загружает историю диалога из Storage
- Отправляет запрос в LLM с историей
- Получает ответ от LLM
- Сохраняет обновленную историю (user message + assistant message)
- Отправляет ответ пользователю
- При длинных ответах (>4096 символов) - разбивает на несколько сообщений

### 3. Установка роли - `/role`

**Установка кастомной роли:**
- Команда: `/role <текст системного промпта>`
- Пример: `/role Ты опытный Python разработчик. Помогаешь с кодом и архитектурой.`
- Без ограничений на длину промпта

**Возврат к роли по умолчанию:**
- Команда: `/role default`
- Устанавливает системный промпт из конфигурации

**Поведение:**
- Очищает текущую историю диалога (начинает новый диалог с новой ролью)
- Сохраняет новый системный промпт в файле пользователя
- Подтверждает установку роли с первыми 100 символами промпта

### 4. Сброс истории - `/reset`

- Очищает историю сообщений
- Сохраняет текущий системный промпт (не сбрасывает роль)
- Подтверждает сброс с информацией о текущей роли

### 5. Статус - `/status`

Показывает информацию:
- Количество сообщений в текущей истории
- Текущий системный промпт (первые 100 символов)
- Дата последнего обновления диалога
- Используемая модель LLM

### 6. Справка - `/help`

Список всех команд:
- `/start` - начать работу с ботом
- `/role <промпт>` - установить роль ассистента
- `/role default` - вернуться к роли по умолчанию
- `/reset` - очистить историю диалога
- `/status` - показать статус и статистику
- `/help` - показать эту справку

### Обработка ошибок

- LLM недоступен → автоматически переключаемся на fallback модель
- Обе модели недоступны → сообщаем и предлагаем повторить позже
- Некорректная команда → подсказываем `/help`
- `/role` без текста → показываем пример использования

---

## 8. Конфигурирование

### Способ конфигурирования

- **Файл `.env`** - все настройки в одном месте (по умолчанию в корне проекта)
- **Переменные окружения** - приоритет над .env (для продакшена)
- **Аргумент командной строки** - `--env-file` для указания пути к .env (через встроенный `argparse`)
- **Pydantic** - валидация и типизация конфигурации
- **`.env.example`** - шаблон с описанием всех параметров

### Структура конфигурации (.env)

```bash
# Telegram Bot
TELEGRAM_TOKEN=your_bot_token_here

# OpenRouter LLM
OPENROUTER_API_KEY=your_api_key_here
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet
OPENROUTER_FALLBACK_MODEL=meta-llama/llama-3.1-8b-instruct:free

# System Prompt
SYSTEM_PROMPT=Ты полезный ассистент. Отвечай на вопросы пользователей четко и по делу.

# LLM Parameters
LLM_TEMPERATURE=0.7
LLM_MAX_TOKENS=1000
MAX_HISTORY_MESSAGES=50

# Retry Configuration
RETRY_ATTEMPTS=3
RETRY_DELAY=1.0

# Directories
DATA_DIR=data
LOGS_DIR=logs

# Logging
LOG_LEVEL=INFO
```

### Запуск с кастомным .env

```bash
# Запуск с .env из другого места
python -m src.main --env-file /path/to/custom.env

# Запуск с .env по умолчанию
python -m src.main
```

**Примечание:** Парсинг аргументов командной строки реализован через встроенный модуль `argparse` (без дополнительных зависимостей).

### Принципы конфигурирования

1. **Все секреты в .env** - токены и ключи не в коде, не в git
2. **Значения по умолчанию** - разумные дефолты для необязательных параметров
3. **Валидация при старте** - приложение не запустится с невалидной конфигурацией
4. **Понятные имена** - каждый параметр самоочевиден
5. **Один источник истины** - Config класс предоставляет настройки всем компонентам
6. **Гибкость** - можно использовать разные .env для разных окружений

### Обработка ошибок конфигурации

- Отсутствует обязательный параметр → понятное сообщение какой именно параметр нужен
- Невалидное значение → сообщение с ожидаемым форматом/типом
- Файл .env не найден → попытка использовать переменные окружения или ошибка
- Невалидный путь к .env → понятное сообщение об ошибке

### Приоритет загрузки настроек

1. Аргументы командной строки (путь к .env)
2. Переменные окружения
3. Файл .env
4. Значения по умолчанию (если применимо)

---

## 9. Логирование

### Инструменты

- **Встроенный модуль `logging`** Python - без дополнительных зависимостей
- **RotatingFileHandler** - ротация логов по размеру (встроенный)
- **Форматированный вывод** - читаемые логи с временем и контекстом

### Уровни логирования

- **DEBUG** - детальная информация для отладки (все вызовы API, детали Storage)
- **INFO** - ключевые события (старт бота, обработка команд, успешные LLM запросы)
- **WARNING** - предупреждения (retry попытки, длинные сообщения)
- **ERROR** - ошибки (провал LLM запроса, ошибки Storage, исключения)

### Что логируем

**Запуск приложения:**
- Версия Python, загруженная конфигурация (без секретов)
- Инициализация компонентов (Bot, Storage, LLMClient)
- Успешный запуск polling

**Telegram бот:**
- Входящие команды (user_id, команда)
- Входящие сообщения (user_id, длина текста)
- Отправленные ответы (user_id, длина ответа)

**LLM операции:**
- Запросы (user_id, модель, количество сообщений в истории)
- Ответы (использованные токены, время выполнения)
- Ошибки и retry попытки
- Переключение на fallback модель (причина, результат)

**Storage:**
- Чтение/запись файлов (user_id, путь к файлу)
- Создание новых диалогов
- Ошибки работы с файловой системой

**Ошибки и исключения:**
- Полный stack trace
- Контекст выполнения (что делали, какие данные обрабатывали)

### Формат лога

```
2025-10-10 12:00:00,123 | INFO     | bot.py:45              | Bot started successfully
2025-10-10 12:00:05,456 | INFO     | message_handler.py:78  | User 123456: received message (15 chars)
2025-10-10 12:00:05,500 | INFO     | llm_client.py:120      | LLM request: model=claude-3.5-sonnet, messages=5
2025-10-10 12:00:07,890 | INFO     | llm_client.py:145      | LLM response: tokens=150/50/200, time=2.3s
2025-10-10 12:00:10,123 | WARNING  | llm_client.py:130      | LLM request failed, retrying (attempt 1/3)
2025-10-10 12:00:15,789 | ERROR    | storage.py:89          | Failed to save dialog: [Errno 13] Permission denied
```

### Хранение логов

**Консоль (stdout):**
- Используется при разработке
- Тот же формат, без цветов
- Уровень из конфигурации

**Файл:**
- Путь: `logs/bot.log`
- Ротация по размеру: максимум 10MB на файл
- Хранение: последние 5 файлов
- Формат: текст, одна строка = один лог-запись
- Легко парсится стандартными инструментами

### Конфигурация логирования

- Уровень: из переменной `LOG_LEVEL` в .env
- Директория: из переменной `LOGS_DIR` в .env
- Настройка: в `main.py` при старте приложения
- Автоматическое создание директории `logs/` если не существует

### Принципы логирования

1. **Не логируем секреты** - токены, API ключи маскируются
2. **Контекст всегда** - каждый лог содержит достаточно информации
3. **Читаемость** - логи должны быть понятны человеку
4. **Производительность** - минимальное влияние на работу приложения
5. **Простота** - используем только встроенные средства Python

---

## 10. DevOps

### Цель

Унифицированная среда разработки в Docker контейнере для изоляции и воспроизводимости окружения.

### Docker для разработки

**Базовый образ:**
- `python:3.11-alpine` - минимальный оптимизированный образ (~50MB)
- Установка только необходимых системных зависимостей

**Особенности контейнера:**
- Volume mounting для live-reload кода (изменения применяются сразу)
- Проброс директорий: `./src`, `./data`, `./logs`
- Поддержка переменных окружения из `.env`
- Кеширование зависимостей для ускорения пересборки

**Dockerfile.dev структура:**
- Multi-stage сборка для оптимизации
- Отдельный слой для установки зависимостей (кеширование)
- Рабочая директория `/app`
- Non-root пользователь для безопасности

**docker-compose.yml:**
- Один сервис для бота
- Автоматический restart при сбоях
- Volume mapping для кода и данных
- Переменные окружения из `.env`

### Оптимизация контейнера

**Alpine Linux:**
- Минимальный размер базового образа (~50MB вместо ~900MB Debian)
- Быстрая загрузка и сборка
- apk package manager

**Кеширование:**
- Зависимости устанавливаются отдельным слоем
- Пересборка только при изменении `pyproject.toml`
- Код копируется последним слоем

**Минимализм:**
- Только необходимые системные пакеты
- `.dockerignore` исключает ненужные файлы
- Отсутствие dev-инструментов в контейнере

### Makefile команды

```makefile
# Качество кода
format            # Отформатировать код (ruff format)
lint              # Проверить линтером (ruff + mypy)
pre-commit-install # Установить pre-commit hooks
ci                # Запустить все проверки (format + lint)

# Тестирование
test              # Запустить тесты с coverage
test-fast         # Запустить тесты без coverage

# Docker команды для разработки
docker-build      # Собрать образ для разработки
docker-up         # Запустить контейнер (с live reload)
docker-down       # Остановить контейнер
docker-logs       # Показать логи контейнера
docker-shell      # Войти в shell контейнера
docker-restart    # Перезапустить контейнер
docker-clean      # Удалить контейнер и volumes

# Локальные команды (без Docker)
install           # Установить зависимости через uv
run               # Запустить бота локально
clean             # Очистить временные файлы
```

### Структура файлов

```
ai-tg-bot/
├── Dockerfile.dev           # Образ для разработки (Alpine)
├── docker-compose.yml       # Оркестрация для разработки
└── .dockerignore            # Исключения для Docker
```

### Два режима работы

**1. С Docker (рекомендуется для разработки):**
```bash
make docker-up
# Контейнер запускается с volume mapping
# Изменения в коде применяются автоматически
```

**2. Без Docker (локальный запуск):**
```bash
make install
make run
# Обычный запуск Python приложения
```

### Преимущества Docker для разработки

- ✅ Изолированное окружение
- ✅ Одинаковая среда у всех разработчиков
- ✅ Не загрязняет систему зависимостями
- ✅ Легко переключаться между проектами
- ✅ Воспроизводимость багов

### Принципы

1. **Простота** - минимальная конфигурация Docker
2. **Производительность** - Alpine образ + кеширование слоев
3. **Гибкость** - приложение работает с Docker и без него
4. **Изоляция** - окружение разработки не влияет на систему

---

## 11. Качество кода и тестирование

### Инструменты качества кода

**Ruff - линтер и форматтер:**
- Единый инструмент вместо black, flake8, isort
- Максимальная длина строки: 100 символов
- Автоматическое форматирование
- Быстрая работа (написан на Rust)

**Mypy - статическая проверка типов:**
- Строгий режим (`strict = true`)
- Проверка всех type hints
- Выявление ошибок до runtime
- Улучшение читаемости кода

**Pre-commit hooks:**
- Автоматическая проверка перед каждым коммитом
- Форматирование, линтинг, проверка типов
- Невозможно закоммитить код с ошибками
- Установка: `make pre-commit-install`

### Стандарты форматирования

**Правила Ruff:**
- E, F - базовые ошибки PEP 8
- I - сортировка импортов
- N - именование переменных и функций
- W - предупреждения
- UP - современный Python синтаксис
- B - потенциальные баги
- C4 - оптимизация comprehensions
- SIM - упрощения кода
- ARG - неиспользуемые аргументы

**Конфигурация в `pyproject.toml`:**
```toml
[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = ["E", "F", "I", "N", "W", "UP", "B", "A", "C4", "DTZ", "T20", "RET", "SIM", "ARG"]
ignore = ["E501"]

[tool.mypy]
python_version = "3.11"
strict = true
```

### Архитектура тестирования

**Фреймворк: pytest + pytest-asyncio + pytest-cov**

**Структура тестов:**
```
tests/
├── conftest.py          # Общие фикстуры
├── test_storage.py      # Тесты Storage
├── test_llm_client.py   # Тесты LLMClient
└── test_handlers.py     # Тесты handlers
```

**Фикстуры (conftest.py):**
- `tmp_path` - временная директория для тестов
- `config_factory` - создание тестовой конфигурации
- `mock_llm_client` - мок LLM клиента

**Покрытие кода:**
- Минимум 70% для Storage и LLMClient
- Отчет в терминале и HTML
- Проверка в CI/CD

### Что тестируем

**✅ Обязательно тестируем:**
- **Storage**: загрузка/сохранение истории, лимиты, промпты
- **LLMClient**: успешные запросы, retry, обработка ошибок
- **Utils**: разбивка сообщений, форматирование ошибок

**✅ Желательно тестируем:**
- **Handlers**: обработка команд
- **Config**: валидация настроек

**❌ Не тестируем:**
- Внешние API (используем моки)
- Telegram Bot API (используем моки)
- UI/UX поведение

### Процесс разработки с тестами

**1. Перед коммитом:**
```bash
make format  # Форматирование
make lint    # Линтер + mypy
make test    # Тесты с coverage
```

**2. Pre-commit hooks автоматически:**
- Форматируют код
- Запускают линтер
- Проверяют типы
- Блокируют коммит при ошибках

**3. В CI/CD:**
- Все проверки качества
- Запуск всех тестов
- Проверка минимального coverage
- Блокировка merge при ошибках

### Best Practices

**Async/await:**
- Использовать `aiofiles` для файловых операций
- Не блокировать event loop
- Избегать `run_in_executor` для I/O

**SOLID принципы:**
- Single Responsibility - один класс = одна задача
- Зависимости через параметры, не через глобальные переменные
- Маленькие специфичные интерфейсы

**DRY (Don't Repeat Yourself):**
- Выносить общую логику в функции
- Использовать декораторы для повторяющихся паттернов
- Создавать утилиты для часто используемых операций

**Error Handling:**
- Специфичные исключения (LLMAPIError)
- Явная обработка ошибок
- Логирование с контекстом
- Понятные сообщения пользователю

---

## Заключение

Данный документ описывает техническое видение MVP проекта LLM-ассистента в виде Telegram-бота с акцентом на качество кода и best practices.

**Ключевые принципы:**
- **KISS** - простота во всем
- **SOLID** - архитектурные принципы ООП
- **DRY** - избегаем дублирования кода
- **Качество** - автоматические проверки на каждом этапе
- **Тестирование** - минимум 70% покрытия критической логики
- **Минимализм** - только необходимые зависимости
- **Быстрый старт** - простая настройка и запуск
- **Поддерживаемость** - легко читать, изменять и расширять

**Инструменты качества:**
- Ruff - форматирование и линтинг
- Mypy - проверка типов
- Pytest - тестирование
- Pre-commit - автоматизация проверок
- CI/CD - непрерывная интеграция

**Архитектурные улучшения:**
- Разделение bot.py на handlers и utils (SRP)
- Async I/O через aiofiles вместо run_in_executor
- Покрытие кода тестами
- Автоматический контроль качества

Документ служит основой для разработки и постоянно дополняется по мере развития проекта. Следование этим принципам гарантирует создание качественного, поддерживаемого и расширяемого решения.

**Добавлено в последнем обновлении:**
- Fallback механизм для повышения надежности
- Автоматическое переключение на резервную модель при сбоях
- Конфигурация резервной модели

**Дата последнего обновления**: 2025-10-11

