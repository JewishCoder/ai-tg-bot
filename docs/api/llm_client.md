# üß† LLM Client API

## –û–±–∑–æ—Ä

`LLMClient` - –∫–ª–∏–µ–Ω—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Large Language Models —á–µ—Ä–µ–∑ OpenRouter API.

## –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- ‚úÖ –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å OpenRouter API
- ‚úÖ Retry –º–µ—Ö–∞–Ω–∏–∑–º –¥–ª—è API –≤—ã–∑–æ–≤–æ–≤
- ‚úÖ Fallback –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å–±–æ—è—Ö
- ‚úÖ –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–ª—É–∂–µ–±–Ω—ã—Ö –ø–æ–ª–µ–π (`id`, `timestamp`)
- ‚úÖ –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ token usage
- ‚úÖ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

## –ö–ª–∞—Å—Å `LLMClient`

### –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è

```python
from src.llm_client import LLMClient
from src.config import Config

config = Config()
llm_client = LLMClient(config)
```

## –û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥

### `async generate_response(messages: list[dict[str, str]], user_id: int) -> str`

–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç LLM –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞.

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- `messages` (list[dict]): –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ OpenAI
  - `role` (str): "system" | "user" | "assistant"
  - `content` (str): –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è
- `user_id` (int): ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è

**–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:**
- `str`: –¢–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞ –æ—Ç LLM

**–ò—Å–∫–ª—é—á–µ–Ω–∏—è:**
- `LLMAPIError`: –ü—Ä–∏ –æ—à–∏–±–∫–µ API –ø–æ—Å–ª–µ –≤—Å–µ—Ö retry –ø–æ–ø—ã—Ç–æ–∫

**–ü—Ä–∏–º–µ—Ä:**
```python
messages = [
    {"role": "system", "content": "–¢—ã - –ø–æ–ª–µ–∑–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç"},
    {"role": "user", "content": "–ü—Ä–∏–≤–µ—Ç!"}
]

response = await llm_client.generate_response(messages, user_id=12345)
print(response)  # "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?"
```

## Retry –º–µ—Ö–∞–Ω–∏–∑–º

LLM Client –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –Ω–µ—É–¥–∞—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã:

```mermaid
graph TD
    A[API –∑–∞–ø—Ä–æ—Å] --> B{–£—Å–ø–µ—Ö?}
    B -->|–î–∞| C[–í–æ–∑–≤—Ä–∞—Ç –æ—Ç–≤–µ—Ç–∞]
    B -->|–ù–µ—Ç| D{Retry?}
    D -->|Rate limit| E[Retry —á–µ—Ä–µ–∑ N —Å–µ–∫]
    D -->|Connection| E
    D -->|–î—Ä—É–≥–∏–µ| F{Fallback<br/>–º–æ–¥–µ–ª—å?}
    F -->|–î–∞| G[–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å<br/>fallback]
    F -->|–ù–µ—Ç| H[LLMAPIError]
    E --> I{–ü–æ–ø—ã—Ç–∫–∏<br/>–∏—Å—á–µ—Ä–ø–∞–Ω—ã?}
    I -->|–ù–µ—Ç| A
    I -->|–î–∞| F
    G --> J{–£—Å–ø–µ—Ö?}
    J -->|–î–∞| C
    J -->|–ù–µ—Ç| H
```

### –ü–∞—Ä–∞–º–µ—Ç—Ä—ã retry

- `max_retries` (default: 3): –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
- `retry_delay` (default: 1.0s): –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏

**Retry –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–ª—è:**
- `RateLimitError` (429) - –ø—Ä–µ–≤—ã—à–µ–Ω –ª–∏–º–∏—Ç –∑–∞–ø—Ä–æ—Å–æ–≤
- `APIConnectionError` - –ø—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ç—å—é
- `APIError` (5xx) - —Å–µ—Ä–≤–µ—Ä–Ω—ã–µ –æ—à–∏–±–∫–∏

**Retry –ù–ï –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –¥–ª—è:**
- `APITimeoutError` - —Ç–∞–π–º–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞
- `AuthenticationError` - –Ω–µ–≤–µ—Ä–Ω—ã–π API –∫–ª—é—á
- `BadRequestError` (4xx, –∫—Ä–æ–º–µ 429) - –Ω–µ–≤–µ—Ä–Ω—ã–π –∑–∞–ø—Ä–æ—Å

## Fallback –º–µ—Ö–∞–Ω–∏–∑–º

–ü—Ä–∏ –ø–æ—Å—Ç–æ—è–Ω–Ω—ã—Ö —Å–±–æ—è—Ö –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ—Ç—Å—è –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—É—é.

### –ö–æ–≥–¥–∞ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç fallback?

- –ü–æ—Å–ª–µ –∏—Å—á–µ—Ä–ø–∞–Ω–∏—è retry –ø–æ–ø—ã—Ç–æ–∫
- –¢–æ–ª—å–∫–æ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –æ—à–∏–±–æ–∫ (rate limit, API errors)
- –ï—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ `openrouter_fallback_model`

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

```python
config = Config(
    openrouter_model="deepseek/deepseek-chat",  # –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å
    openrouter_fallback_model="deepseek/deepseek-chat-v3.1:free",  # Fallback
)
```

**–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã:**
```python
# 1. –ü–æ–ø—ã—Ç–∫–∞ —Å –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª—å—é
response = await client._make_api_call(messages, "deepseek/deepseek-chat")
# ‚ùå Rate limit exceeded (–ø–æ—Å–ª–µ 3 retry)

# 2. Fallback –Ω–∞ —Ä–µ–∑–µ—Ä–≤–Ω—É—é –º–æ–¥–µ–ª—å
if should_try_fallback(error):
    response = await client._make_api_call(messages, "deepseek/deepseek-chat-v3.1:free")
    # ‚úÖ –£—Å–ø–µ—Ö!
```

## –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–ª—É–∂–µ–±–Ω—ã—Ö –ø–æ–ª–µ–π

Client –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ API:

```python
# –í—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ (–∏–∑ Storage)
messages = [
    {
        "id": "uuid-123",              # ‚Üê –§–∏–ª—å—Ç—Ä—É–µ—Ç—Å—è
        "role": "user",
        "content": "Hello",
        "timestamp": "2024-01-01..."   # ‚Üê –§–∏–ª—å—Ç—Ä—É–µ—Ç—Å—è
    }
]

# –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –≤ API
api_messages = [
    {
        "role": "user",
        "content": "Hello"
    }
]
```

## –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

### Token usage

```python
logger.info(
    f"User {user_id}: LLM response generated "
    f"(model: {model}, tokens: {tokens})"
)
```

### –û—à–∏–±–∫–∏

```python
logger.error(
    f"User {user_id}: LLM API error after {attempts} attempts: {error}"
)
```

### Fallback

```python
logger.warning(
    f"User {user_id}: Falling back to {fallback_model} after primary model failure"
)
```

## –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏

–ù–∞—Å—Ç—Ä–∞–∏–≤–∞—é—Ç—Å—è —á–µ—Ä–µ–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é:

```python
config = Config(
    openrouter_model="deepseek/deepseek-chat",
    openrouter_temperature=0.7,      # –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å (0.0-2.0)
    openrouter_max_tokens=1000,      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞
)
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã OpenAI API:**
- `temperature`: –ö—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ (0.0 = –¥–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π, 2.0 = –æ—á–µ–Ω—å –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π)
- `max_tokens`: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ

## –ò—Å–∫–ª—é—á–µ–Ω–∏—è

### `LLMAPIError`

–ë–∞–∑–æ–≤–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö –æ—à–∏–±–æ–∫ LLM API.

```python
from src.llm_client import LLMAPIError

try:
    response = await llm_client.generate_response(messages, user_id)
except LLMAPIError as e:
    print(f"LLM API error: {e}")
```

**–ö–æ–≥–¥–∞ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ—Ç—Å—è:**
- –ü–æ—Å–ª–µ –≤—Å–µ—Ö retry –ø–æ–ø—ã—Ç–æ–∫
- –ü–æ—Å–ª–µ –Ω–µ—É–¥–∞—á–Ω–æ–≥–æ fallback (–µ—Å–ª–∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω)
- –ü—Ä–∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–∫–∞—Ö (auth, bad request)

## –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è

### –ë–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ

```python
from src.llm_client import LLMClient
from src.config import Config

config = Config()
client = LLMClient(config)

messages = [
    {"role": "system", "content": "–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ Python"},
    {"role": "user", "content": "–ß—Ç–æ —Ç–∞–∫–æ–µ list comprehension?"}
]

response = await client.generate_response(messages, user_id=12345)
print(response)
```

### –° –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫

```python
from src.llm_client import LLMClient, LLMAPIError

try:
    response = await client.generate_response(messages, user_id)
except LLMAPIError as e:
    print(f"–û—à–∏–±–∫–∞ API: {e}")
    response = "–ò–∑–≤–∏–Ω–∏—Ç–µ, —Å–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"
```

### –° fallback –º–æ–¥–µ–ª—å—é

```python
config = Config(
    openrouter_model="gpt-4",
    openrouter_fallback_model="gpt-3.5-turbo",
)

client = LLMClient(config)

# –ï—Å–ª–∏ gpt-4 –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—Å—è –Ω–∞ gpt-3.5-turbo
response = await client.generate_response(messages, user_id)
```

### –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∏—Å—Ç–æ—Ä–∏–∏

```python
# –ò—Å—Ç–æ—Ä–∏—è –∏–∑ Storage —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è
history = await storage.load_history(user_id)

# LLMClient –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç –∏—Ö
response = await llm_client.generate_response(history, user_id)
```

## –ü—Ä–∏–≤–∞—Ç–Ω—ã–µ –º–µ—Ç–æ–¥—ã

### `async _make_api_call(messages: list[dict], model: str) -> str`

–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–∏–Ω API –∑–∞–ø—Ä–æ—Å –∫ OpenRouter.

### `_should_try_fallback(error: Exception) -> bool`

–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ø—Ä–æ–±–æ–≤–∞—Ç—å fallback –º–æ–¥–µ–ª—å.

### `_filter_message_fields(messages: list[dict]) -> list[dict]`

–§–∏–ª—å—Ç—Ä—É–µ—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–æ–ª—è –∏–∑ —Å–æ–æ–±—â–µ–Ω–∏–π.

## –ê—Ç—Ä–∏–±—É—Ç—ã

| –ê—Ç—Ä–∏–±—É—Ç | –¢–∏–ø | –û–ø–∏—Å–∞–Ω–∏–µ |
|---------|-----|----------|
| `config` | Config | –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è |
| `client` | OpenAI | OpenAI –∫–ª–∏–µ–Ω—Ç (–¥–ª—è OpenRouter) |

## –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –º–æ–¥–µ–ª–∏

LLM Client —Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏, –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ —á–µ—Ä–µ–∑ OpenRouter:

**–ü–æ–ø—É–ª—è—Ä–Ω—ã–µ –º–æ–¥–µ–ª–∏:**
- `deepseek/deepseek-chat` - DeepSeek V3 (–±—ã—Å—Ç—Ä–∞—è –∏ –¥–µ—à–µ–≤–∞—è)
- `deepseek/deepseek-chat-v3.1:free` - –ë–µ—Å–ø–ª–∞—Ç–Ω–∞—è –≤–µ—Ä—Å–∏—è
- `anthropic/claude-3.5-sonnet` - Claude 3.5 Sonnet
- `openai/gpt-4` - GPT-4
- `openai/gpt-3.5-turbo` - GPT-3.5 Turbo
- `meta-llama/llama-3.1-70b-instruct` - Llama 3.1 70B

–°–º. [OpenRouter Models](https://openrouter.ai/models) –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞.

## –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### Retry strategy

- –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π backoff –¥–ª—è rate limits
- –ë—ã—Å—Ç—Ä—ã–π retry –¥–ª—è —Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–æ–∫
- –ü—Ä–æ–ø—É—Å–∫ retry –¥–ª—è –Ω–µ–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏–º—ã—Ö –æ—à–∏–±–æ–∫

### –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ

- Minimal logging –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- –î–µ—Ç–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—à–∏–±–æ–∫
- Token usage tracking

## –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

- `openai`: OpenAI Python SDK (–¥–ª—è OpenRouter)
- `src.config.Config`: –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

## –°–º. —Ç–∞–∫–∂–µ

- [OpenRouter API Docs](https://openrouter.ai/docs)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)
- [Config](../../src/config.py)

